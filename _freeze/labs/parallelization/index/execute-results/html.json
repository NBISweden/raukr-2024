{
  "hash": "2f10b4ddb4ac5b424b2e88011e04c788",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Parallelization\"\nauthor: \"Sebastian DiLorenzo\"\ndescription: \"Speed up your code through parallel computing.\"\nimage: \"assets/featured.jpg\"\nformat: html\n---\n\n\n\n\n::: {.callout-note}\nThis is the parallelization lab. It will take you through some basic steps to parallelize your code and try to make you think about when and where you can use this tool.\n\nYou are highly encouraged to test things out yourself and tweak things to figure out how these methods behave.\n:::\n\n## Install\n\nThe first thing we want to do is install the package required for the exercise.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"future\")\n```\n:::\n\n\n## Exercises\n\nThe basic construct for a future is this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\na %<-% { expression(s) }\n```\n:::\n\n\nHere is a computationally intensive task that samples numbers from 1:100, 200000000 times.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample(100,200000000,replace=T)\n```\n:::\n\n\nEvaluating the computation time on my machine, it comes out taking about 5.4 seconds to run.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsystem.time(sample(100,200000000,replace=T))\n   user  system elapsed \n  5.173   0.160   5.369 \n```\n:::\n\n\n### Sequential and Multi-\n\n- Use the future package with `plan(sequential)`,which is the default, and run the supplied `sample()` inside a future.\n\n::: {.callout-note}\nThere is a warning message when generating random numbers without seed. We can ignore this by changing our options: `options(future.rng.onMisuse=\"ignore\")`.\n:::\n\n- Add an approach from yesterdays lecture on benchmarking or some other way that you are comfortable with to calculate the time it takes to complete the operation of simply assigning the future. Do not evaluate the future yet by asking for the outcome value.\n\n::: {.callout-note}\nYou should not attempt to calculate times taken within the future, always wrap this around futures.\n:::\n\n**Question 1:** Split your sampling into multiple futures and compute the time again. Did it complete faster?\n<!-- No, because we are on plan sequential -->\n\n**Question 2:** Change to `plan(multisession)` or `plan(multicore)` according to your setup (operating system type, RStudio or just console). Compute the time again for your multiple futures. Did it complete faster? Think about what the time it takes to compute implies.\n<!-- No. Because we are just sending out the futures. Not resolving them. -->\n\n::: {.callout-note}\nSometimes there are issues running `plan(multicore)` and even `plan(multisession)` in Rstudio. If this happens, you might want to just start R console from a terminal window.\n:::\n\n**Question 3:** Ask for the outcome of your futures after their definitions, thus evaluating them. How does this influence the time it takes to perform the operations?\n<!-- It increases the time because of the unblocked R process. In this case it is actually measuring the time until resolved while in the previous question it is just measuring the time to send out the futures.-->\n\nAt this stage your code should, in **pseudocode**, look something like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplan(multisession)\n\ntimer(\n  a %<-% {sample expression}\n  b %<-% {sample expression}\n  #evaluate futures by requesting outcome values\n  a + b\n)\n```\n:::\n\n\n**Question 4:** If you have more than two `availableCores()`, split the `sample()` expression to even more futures . Does this influence time to complete in the manner you thought?\n<!-- This should slightly lower compute time, but probably not quite as much as some would think. Bigger influence for larger processes as here other surrounding operations use a bit of the time. -->\n\n### Errors\n\n-   Introduce an error in one of your future expressions.\n\n**Question 5:** Does the error output when the future is defined and unresolved, or when it is resolved?\n<!-- This depends on the type of error, but usually it shows when it is resolved-->\n\n[Further reading about errors and debugging for futures.](https://github.com/HenrikBengtsson/future#failed-futures)\n\n### for loops\n\nTo use futures in for loops we can use named indices to assign the future to environments. This is pretty similar to assigning values to named indices with the normal assigner `<-`, the main difference being that we need to use new environments and we can have multiple expressions for futures.\n\nFor example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplan(multisession)\n\n#Create a new environment\nv <- new.env()\nfor (name in c(\"a\", \"b\", \"c\")) {\n  v[[name]] %<-% {\n        #expression(s)\n     }\n}\n#Turn the environment back into a list\nv <- as.list(v)\n\n#To turn the list of vectors into the same format, one long vector, that we had above when running \"a + b + c\"\nvec <- Reduce(c,v)\n```\n:::\n\n\n- Use this to divide the `sample()` operation into however many smaller pieces you want. Do remember to transform your output back into the object we started with before parallelizing the execution.\n\nNow you know the basics of using the `future` package. With this you have already come a long way in lowering the threshold to implement parallel methods and seeing parallel solutions when you run into it next!\n\n## Extra credit\n\nTry to apply parallelization to your own code in a different context than we have done here. For example dividing up a plot or a large dataset. The possibilities are endless.\n\n## Recommended further reading\n\nCheck out [futures demo](https://github.com/HenrikBengtsson/future#demos) visualization of sequential vs multicore/session.\n\nUsing futures on HPC clusters with [future.batchtools](https://github.com/HenrikBengtsson/future.batchtools).\n\nUsing futures for your `lapply` statements with [future.apply](https://github.com/HenrikBengtsson/future.apply).\n\nThe published paper on [future](https://journal.r-project.org/archive/2021/RJ-2021-048/RJ-2021-048.pdf).",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}