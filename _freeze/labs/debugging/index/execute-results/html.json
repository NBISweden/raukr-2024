{
  "hash": "c6a2aec2dc28a51238799b35b9d384a2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Debugging, Profiling and Optimizing Code\"\nauthor: \"Marcin Kierczak\"\ndescription: \"Coding debugging, code benchmarking and optimization.\"\nimage: \"assets/featured.jpg\"\nformat: html\n---\n\n::: {.cell}\n\n:::\n\n\n::: {.callout-note}\nThe objective of this lab is to improve your coding skills by focusing on code debugging, benchmarking and optimization. Below, you will find a number of tasks connected to the topics covered in the *Debugging, profiling and optimization* lecture. Some tasks extend lectures content and require you to find some more information online. Please, note that while we are providing example solutions to many tasks, these are only **examples**. If you solve a task in a different way it does not matter your solution is wrong. In fact, it may be better than our solution. If in doubt, ask TA for help. We are here for you!\n:::\n\n## Debugging\n\n### Task: Code Correctness\n\nWhich of the following chunks of code are correct and which contain errors? Identify these errors.\n\n#### Chunk 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninput <- sample(1:1000, size = 1000, replace = T)\ncurrmin <- NULL\nfor (i in input) {\n  if (input > currmin) {\n    currmin <- input\n    print(paste0(\"The new minimum is: \", currmin))\n  }\n}\n```\n:::\n\n\n#### Chunk 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninput <- sample(1:1000, size = 1000, replac = T)\ncurrmin <- NULL\nfor (i in input) {\n  if (input < currmin) {\n    currmin <- input\n    print(paste0(\"The new minimum is: \", currmin))\n  }\n}\n```\n:::\n\n\n#### Chunk 3\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor (cnt in 1:100) {\n  if (cnt > 12) {\n    print(\"12+\")\n  } else {\n    print(\"Not 12+\")\n  }\n}\n```\n:::\n\n\n#### Chunk 4\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresult <- logical(10)\ninput <- sample(1:10, size = 10, replace = T)\nfor (i in 0:length(input)) {\n  if (input[i] >= 5) {\n    result[i] <- TRUE\n  }\n}\n```\n:::\n\n\n### Task: Debugger.\n\nPlay with debugger as described in lecture slides.\n\n### Task: Floating-point Arithmetics.\n\nCan you fix the code below so that it produces more reliable result?\n\n::: {.callout-tip}\nThink in terms of system-specific representation $\\epsilon$.\n:::\n\nPut the value of your double $\\epsilon$ into [this spreadsheet](https://docs.google.com/spreadsheets/d/1_2tDeEkDVS06RkB437yBI1XEB5SUebtHWyxAf_aRJu4/edit?usp=sharing) (Best Coding Practises Lab sheet).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvec <- seq(0.1, 0.9, by=0.1)\nvec == 0.7\n```\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## Example Solution\n\n::: {.cell}\n\n```{.r .cell-code}\n# One way is to use epsilon\n# Check machine's floating point representation\nvec <- seq(0.1, 0.9, by=0.1)\n\n# Make a custom function that uses machines' epsilon for comparing\n# values\nis_equal <- function(x, y) {\n  isEqual <- F\n  if (abs(x - y) < unlist(.Machine)['double.eps']) {\n    isEqual <- T\n  }\n  isEqual\n}\n\n# Some tests\n0.7 == 0.6 + 0.1\nis_equal(0.7, 0.6 + 0.1)\n0.7 == 0.8 - 0.1\nis_equal(0.7, 0.8 - 0.1)\n\n# Now you can use the is_equal to fix the code!\n```\n:::\n\n:::\n\n## Profiling\n\n### Task: Filling A Large Matrix.\n\nCreate a 10 000 x 10 000 matrix and fill it with random numbers (from 1 to 42), first row by row and later column by column. Use `proc.time` to see if there is any difference. Is the measurement reliable? Record the values you got in this spreadsheet:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- 10e3 * 10e3\n\n# By row\nt1 <- proc.time()\nM <- matrix(sample(1:42, size = N, replace = T), nrow = sqrt(N), byrow = T)\nt2 <- proc.time()\n(t2 - t1)\n\n# By column\nt1 <- proc.time()\nM <- matrix(sample(1:42, size = N, replace = T), nrow = sqrt(N), byrow = F)\nt2 <- proc.time()\n(t2 - t1)\n```\n:::\n\n\n### Task: Timing Reliability.\n\nIn the lecture slides, you have seen how to time sampling from Normal Gaussian distribution:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsystem.time(rnorm(n = 10e6))\n```\n:::\n\n\nIs such single measurement reliable? Run the code 100 times, plot and record the mean and the variance of the `elapsed` time. Put these values (elapsed.time mean and variance) into [this spreadsheet](https://docs.google.com/spreadsheets/d/1_2tDeEkDVS06RkB437yBI1XEB5SUebtHWyxAf_aRJu4/edit?usp=sharing) (Best Coding Practises Lab sheet).\n\n::: {.callout-tip collapse=\"true\"}\n## Example Solution\n\n::: {.cell}\n\n```{.r .cell-code}\ntiming <- double(100)\nfor (i in 1:100) {\n  st <- system.time(rnorm(n = 10e6))\n  timing[i] <- st[3]\n}\nboxplot(timing) \nmean(timing)\nvar(timing)\n```\n:::\n\n:::\n\n**Optional**\nAn alternative approach or, more exactly, an alternative notation that achieves the same as the previous chunk of code but in a more compact way makes use of the `replicate`, a wrapper function around `sapply` that simplifies repeated evaluation of expressions. The drawback is you do not get the vector of the actual timing values but the results of calling `system.time` are already averaged for you. Try to read about the `replicate` and use it to re-write the code above. Put the `elapsed.time` into [this spreadsheet](https://docs.google.com/spreadsheets/d/1_2tDeEkDVS06RkB437yBI1XEB5SUebtHWyxAf_aRJu4/edit?usp=sharing) (Best Coding Practises Lab sheet). How does this value compare to calling `system.time` within a loop in the previous chunk of code? Are the values similar?\n\n::: {.callout-tip collapse=\"true\"}\n## Example Solution\n\n::: {.cell}\n\n```{.r .cell-code}\nst2 <- system.time(replicate(n = 100, rnorm(n = 10e6)))\n```\n:::\n\n:::\n\n### Task: Microbenchmarking.\n\nWhile `system.time` might be sufficient most of the time, there is also an excellent package `microbenchmark` that enables more accurate time profiling, aiming at microsecond resolution that most of modern operating systems offer. Most of the benchmarking the `microbenchmark` does is implemented in low-overhead C functions and also the package makes sure to:\n\n- estimate granularity and resolution of timing for your particular OS,\n- warm up your processor before measuring, i.e. wake the processor up from any idle state or likewise. \n\nBegin by installing the `microbenchmark` package.\n\n#### Checking System Time.\n\nCheck the current value of the platform's timer.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmicrobenchmark::get_nanotime()\n```\n:::\n\n\nModify the code below so that it uses the current value of platform's timer:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntiming <- double(100)\nfor (i in 1:100) {\n  st <- system.time(rnorm(n = 10e6))\n  timing[i] <- st[3]\n}\nboxplot(timing)\n```\n:::\n\n\nPut the mean and the variance into [this spreadsheet](https://docs.google.com/spreadsheets/d/1_2tDeEkDVS06RkB437yBI1XEB5SUebtHWyxAf_aRJu4/edit?usp=sharing) (Best Coding Practises Lab sheet, Microbenchmark -- loop)\n\n::: {.callout-tip collapse=\"true\"}\n## Example Solution\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(microbenchmark)\ntiming <- double(100)\nfor (i in 1:100) {\n  nanotime_start <- get_nanotime()\n  rnorm(n = 10e6)\n  nanotime_stop <- get_nanotime()\n  timing[i] <- nanotime_stop - nanotime_start\n}\nmean(timing)\nvar(timing)\nboxplot(timing)\n```\n:::\n\n:::\n\n#### Microtiming Precision.\n\nThere is an experimental function in the `microbenchmark` package that helps the package estimate granularity and resolution of your particular timing subsystem. According to the documentation, *the function measures the overhead of timing a C function call rounds times and returns all non-zero timings observed.*\n\n<br>\nRun the `microtiming_precision` function and put the mean and the variance of the resulting vector into [this spreadsheet](https://docs.google.com/spreadsheets/d/1_2tDeEkDVS06RkB437yBI1XEB5SUebtHWyxAf_aRJu4/edit?usp=sharing) (Best Coding Practises Lab sheet, Microbenchmark -- precision)\n\n::: {.callout-tip collapse=\"true\"}\n## Example Solution\n\n::: {.cell}\n\n```{.r .cell-code}\nprecision <- microbenchmark::microtiming_precision()\nmean(precision)\nvar(precision)\n```\n:::\n\n:::\n\nRun the function one time without assigning its value to a variable and consult the documentation. Compare the output of running the function without assigning the value to a variable, the values stored in the variable by the function upon assignment and the value specified in the documentation.\n\n::: {.callout-tip collapse=\"true\"}\n## Example Solution\n\n::: {.cell}\n\n```{.r .cell-code}\n# In version 1.4-4 of the package, all three ways give different results!\nmicrobenchmark::microtiming_precision()\nprecision <- microbenchmark::microtiming_precision()\n?microbenchmark::microtiming_precision\n```\n:::\n\n:::\n\n#### The Microbenchmark Way.\n\nFinally, let's benchmark our `rnorm` example using `microbenchmark`:\n\n- microbenchmark the `rnorm(n = 10e6)` expression,\n- plot the results using both `ggplot2` and a boxplot (read the `microbenchmark` package documentation),\n- look at the summary of the benchmark,\n- how long does it take to dispatch a simple function that does nothing compared to evaluating a constant and adding two integers?\n\n::: {.callout-tip collapse=\"true\"}\n## Example Solution\n\n::: {.cell}\n\n```{.r .cell-code}\nrequire(microbenchmark)\nrequire(ggplot2)\nmb <- microbenchmark(rnorm(n = 10e6))\nautoplot(mb)\nboxplot(mb)\nsummary(mb)\nf <- function() {}\nmb2 <- microbenchmark(f(), pi, 2+2)\nsummary(mb2)\nautoplot(mb2)\n```\n:::\n\n:::\n\n### Optional Task: More Advanced Profiling.\n\nNow, we will use a even more sophisticated approach to profiling.\n\n#### The `Rprof` way.\n* Write three functions that fill by row a $N \\times N$ matrix $M$ with randomly generated numbers from a vector given as argument `bag`, allow for passing random seed value as function argument with the default value of 42. After filling the matrix with values, add to each and every element of $M$ the number of column the element is in and return such matrix from the function. Functions should: \n\n- `fill_alloc`) -- use memory allocation prior to loop in which the matrix is being filled and allocate memory using `init` value passed as argument and by default set to `NULL`,\n- `fill_noalloc` -- not use memory allocation prior to the loop,\n- `fill_noloop` should not the loop for filling the matrix in. \n\n::: {.callout-warning}\nDo not perform addition of column number in the same loop.\n:::\n\nFollowing this and using `rnorm(1000, mean = 0, sd = 1)`:\n\n- use `Rprof` to profile the functions using the same seed and N=100,\n- use `Rprof` to check whether there is a difference between initializing the matrix using `NULL` and 0 in `fill_alloc`,\n- what happens if $N = 10$ compared to $N = 20$ to $N = 100$? \n\n::: {.callout-tip collapse=\"true\"}\n## Example Solution\n\n::: {.cell}\n\n```{.r .cell-code}\nfill_noloop <- function(N, bag, seed = 42) {\n  set.seed(seed)\n  values <- sample(bag, size = N^2, replace = T)\n  M <- matrix(data = values, nrow = N, byrow = T)\n  for (col_num in 1:N) {\n    M[, col_num] <- M[, col_num] + col_num\n  }\n  return(M)\n}\n\nfill_noalloc <- function(N, bag, seed = 42) {\n  set.seed(seed)\n  values <- sample(bag, size = N^2, replace = T)\n  M <- NULL\n  cnt = 1\n  for (row in 1:N) {\n    row_tmp <- c()\n    for (col in 1:N) {\n      row_tmp <- c(row_tmp, values[cnt])\n      cnt <- cnt + 1\n    }\n    M <- rbind(M, row_tmp)\n  }\n  for (col_num in 1:N) {\n    M[, col_num] <- M[, col_num] + col_num\n  }\n  return(M)\n}\n\nfill_alloc <- function(N, bag, seed = 42, init = NA) {\n  set.seed(seed)\n  values <- sample(bag, size = N^2, replace = T)\n  M <- matrix(rep(init, times=N^2), nrow = N, byrow = T)\n  cnt = 1\n  for (row in 1:N) {\n    for (col in 1:N) {\n      M[row, col] <- values[cnt]\n      cnt <- cnt + 1\n    }\n  }\n  for (col_num in 1:N) {\n    M[, col_num] <- M[, col_num] + col_num\n  }\n  return(M)\n}\n\nsummary <- summaryRprof('profiler_test_fillers.out', memory='both')\nsummary$by.self\n\n# answers to the remaining questions are not given\n```\n:::\n\n:::\n\n### Optimization\n\nHave a look at our answers from the previous task .\n\n* How can you optimize the `fill_alloc` even further (call the optimized version `fill_alloc_opt`)?\n\n::: {.callout-tip collapse=\"true\"}\n## Example Solution\n\n::: {.cell}\n\n```{.r .cell-code}\nfill_alloc_opt <- function(N, bag, seed = 42, init = NA) {\n  set.seed(seed)\n  values <- sample(bag, size = N^2, replace = T)\n  M <- matrix(rep(init, times=N^2), nrow = N, byrow = T)\n  cnt = 1\n  for (row in 1:N) {\n    for (col in 1:N) {\n      M[row, col] <- values[cnt] + col\n      cnt <- cnt + 1\n    }\n  }\n  return(M)\n}\n```\n:::\n\n:::\n\n* Optimize the `fill_noloop` to `fill_noloops` that does not use any loops at all.\n\n::: {.callout-tip collapse=\"true\"}\n## Example Solution\n\n::: {.cell}\n\n```{.r .cell-code}\nfill_noloops <- function(N, bag, seed = 42) {\n  values <- sample(bag, size = N^2, replace = T)\n  inc <- rep(x = 1:N, times = N)\n  M <- matrix(data = values + inc, nrow = N, byrow = T)\n  return(M)\n}\n```\n:::\n\n:::\n\n### Optiona Task: Using the `profr` package.\n\n- Install and load the `profr` package.\n- Use `profr` to profile `fill_noloop`, `fill_noloops` and `fill_alloc_opt`.\n\nPlease use the following function, if you were not able to run `profr::ggplot.profr`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot.profr <- function(data, ..., minlabel = 0.1, angle=0) {\n  if (!requireNamespace(\"ggplot2\", quietly = TRUE))\n    stop(\"Please install ggplot2 to use this plotting method\")\n  data$range <- diff(range(data$time))\n\n  # quiet R CMD check note\n  start <- NULL\n  end <- NULL\n  time <- NULL\n\n  ggplot2::ggplot(as.data.frame(data)) +\n    ggplot2::geom_rect(\n      ggplot2::aes(xmin = start, xmax = end, ymin = level - 0.5, ymax = level + 0.5),\n      fill = \"grey95\", colour = \"black\", size = 0.5) +\n    ggplot2::geom_text(\n      ggplot2::aes(start + range / 60, level, label = f),\n      data = subset(data, time > max(time) * minlabel),\n      size = 4, angle = angle, hjust = 0) +\n    ggplot2::scale_y_continuous(\"time\") +\n    ggplot2::scale_x_continuous(\"level\")\n}\n```\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## Example Solution\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(profr)\n\nRprof(\"profr_noloop.out\", interval = 0.01)\nfill_noloop(1000, rnorm(1000), seed = 42)\nRprof(NULL)\nprofile_noloop_df <- parse_rprof('profr_noloop.out')\n\nRprof(\"profr_noloops.out\", interval = 0.01)\nfill_noloops(100, rnorm(1000), seed = 42)\nRprof(NULL)\nprofile_noloops_df <- parse_rprof('profr_noloops.out')\n\nRprof(\"profr_alloc_opt.out\", interval = 0.01)\nfill_alloc_opt(10, rnorm(1000), seed = 42)\nRprof(NULL)\nprofile_alloc_opt_df <- parse_rprof('profr_alloc_opt.out')\n\nprofr::ggplot.profr(profile_noloop_df)\nprofr::ggplot.profr(profile_noloops_df)\nprofr::ggplot.profr(profile_alloc_opt_df)\n```\n:::\n\n:::\n\n### Optional Task: Using the `profvis` package.\n\n- Install and load the `profvis` package.\n- Use `profvis` to profile `fill_noloop`, and `fill_alloc` functions.\n\n## Optimize Your Code\n\nIn this section, we will deal with some selected ways to optimize your code.\n\n### Task: Fix and Optimize This!\n\nGiven is a function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptimize_me <- function(N = 1000, values = c(1:1e4)) {\n  N = 10; values = c(1:1e4)\n  dat1 <- matrix(size = N^2)\n  for (i in 1:N) {\n    for (j in 1:N) {\n      dat1[i, j] <- sample(values, 1)\n    }\n  }\n  dat0 <- dat1\n  dat1[lower.tri(dat1)] <- t(dat1)[lower.tri(dat1)]\n  \n  dat2 <- NULL \n  for (i in 1:N) {\n    i_tmp <- c()\n    for (j in 1:N) {\n      i_tmp <- c(i_tmp, sample(values, 1))\n    }\n    dat2 <- rbind(dat2, i_tmp)\n  }\n  dat2[lower.tri(dat2)] <- t(dat2)[lower.tri(dat2)]\n \n  M <- dat2\n  for (i in 1:N) {\n    for (j in 1:N) {\n      M[i, j] <- dat1[i, j] * dat2[i, j]\n    }\n  }\n  for (i in 1:N) {\n    for (j in 1:N) {\n      M[i, j] <- M[i, j] + values[3]\n    }\n  }\n  N <- M %*% dat0\n  result <- apply(N, 2, mean)\n  return(result)\n}\n```\n:::\n\n\n- What does it do, step-by-step?\n- Profile it.\n- Is `dat1 <- matrix(size = N^2)` better than `dat1 <- matrix(NA, nrow=N, ncol=N)`?\n- Can you optimize something using `BLAS`?\n- Can you optimize by using `apply` somewhere?\n- Can you optimize `apply` further?\n- What else can you optimize. Do it. Report speed gain and memory gain compared to the original version in [this spreadsheet](https://docs.google.com/spreadsheets/d/1_2tDeEkDVS06RkB437yBI1XEB5SUebtHWyxAf_aRJu4/edit?usp=sharing) (Best Coding Practises Lab sheet, Optimization gains).  \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}