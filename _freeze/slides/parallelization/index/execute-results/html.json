{
  "hash": "f43230d221244dd2636994a1dcf30c35",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Parallelization in R\"\nauthor: \"Sebastian DiLorenzo\"\nimage: \"assets/featured.jpg\"\nformat: revealjs\n---\n\n\n##  {visibility=\"hidden\"}\n\n\n::: {.cell}\n\n:::\n\n\n## Overview\n\n:::: {.columns}\n::: {.column width=\"60%\"}\n-   parallelization\n-   future\n-   plans\n    -   sequential\n    -   multisession/multicluster\n    -   cluster\n:::\n\n::: {.column width=\"40%\"}\n![](https://raw.githubusercontent.com/HenrikBengtsson/future/develop/man/figures/logo.png){width=\"200px\"}\\\n[[HenrikBengtsson/future](https://github.com/HenrikBengtsson/future)]{.smaller}\n:::\n::::\n\n::: notes\nFuture package has backup packages, for example **future.batchtools** which provides access to cluster functions, like slurm, torque, SGE and LSF. Futures are evaluated in a local environment, meaning that you cant change variables in there. Like in functions.\n\nThe big thing about futures is that it seems to support most infrastructures and it is written in a way where you are not deciding which infrastructure the user has, which parallel and foreach did. Finish with info that he has described this in detail for those that want to know more.\n:::\n\n## parallelization\n\n:::: {.columns}\n::: {.column width=\"60%\"}\n<br> ![](assets/parallel.png){width=\"100%\"}\n:::\n\n::: {.column width=\"40%\"}\n<br>\n\n-   Save time by doing atomic tasks in parallel\n\n<br>\n\n-   Divide tasks or datasets into smaller pieces\n\n<br>\n\n-   Can bottleneck if tasks are directly dependent\n:::\n::::\n\n## R-package: future\n\nOther packages decide the parallelization method during development. With future the code is the same and the USER decides parallelization method.\n\n- Very simple\n- Uniform code, no matter the strategy\n- User defined parallelization\n- Unblocked R process during resolving of futures process\n- Works well on multiple architectures\n\n::: {.aside}\nPublished 2021-06-08 in \"The R Journal\": [A Unifying Framework for Parallel and Distributed Processing in R using Futures](https://journal.r-project.org/archive/2021/RJ-2021-048/RJ-2021-048.pdf)\n:::\n\n::: {.notes}\nR package developers rarely know who the end-users are and what compute resources they have. With future, instead of programming for one architecture, the code should work on most architectures. We will get back to the Unblocked R process during resolving but basically what it means is that even if multiple things are being computed in parallel the R code can continue unblocked until the resolved values are needed.\n\nText from article: The state of a future can either be unresolved or resolved. As soon as it is resolved, the value is available instantaneously. If the value is queried while the future is still unresolved, the current process is blocked until the future is resolved.\n\nR package developers rarely know who the end-users are and what compute resources they have. Regardless, developers who wish to support parallel processing still face the problem of deciding which parallel framework to target, a decision which often has to be done early in the development cycle. This means deciding on what type of parallelism to support, This decision is critical because it limits the end-user's options and any change, later on, might be expensive because of, for instance, having to rewrite and retest part of the codebase. A developer who wishes to support multiple parallel backends has to implement support for each of them individually and provide the end-user with a mechanism to choose between them.\n:::\n\n. . .\n\n<br> Building block: `variable %<-% {expression(s)}`\n\n## Plans\n\n![](assets/plans.png)\n\n::: {.notes}\nSynchronus: existing or occurring at the same time.\n\nAsynchronus: Not occurring or existing at the same time\n\nSequential: One after another. Default. Very useful when developing the code the first time.\n\nmultisession: All operating systems. Evaluated in background R sessions. Number of sessions decided by availableCores().\n\nmulticore: operating systems supporting forking of processes, all except windows. Forks existing R process rather than creating new sessions. Max forks decided by availableCores().\n\nCluster: Cluster environment, such as HPC. Uses package parallel\n:::\n\n## plan(sequential)\n\n<br>\n\nBuilding block: `variable %<-% {expression(s)}`\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"1|3-6|7-10|12\"}\nfuture::plan(sequential)\n\na %<-% {\n  Sys.sleep(3)\n  a <- 1\n}\nb %<-% {\n  Sys.sleep(3)\n  b <- 2\n}\n\na + b\n```\n:::\n\n\n::: {.notes}\nIn programming, a future is an abstraction for a value that may be available at some point in the future. The state of a future can either be unresolved or resolved. As soon as it is resolved, the value is available instantaneously. If the value is queried while the future is still unresolved, the current process is blocked until the future is resolved. It is possible to check whether a future is resolved or not without blocking.\n:::\n\n. . .\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3\n   user  system elapsed \n  0.041   0.004   6.050 \n```\n\n\n:::\n:::\n\n\n## plan(multisession) & plan(multicore)\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nplan(multicore)\n\na %<-% {\n  Sys.sleep(3)\n  a <- 1\n}\nb %<-% {\n  Sys.sleep(3)\n  b <- 2\n}\n\na + b\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3\n   user  system elapsed \n  0.034   0.037   3.053 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n::: {.notes}\nNote: To compute `plan(multicore)` the rmarkdown must be rendered from terminal r console, as rstudio does not support multicore. `rmarkdown::render(\"parallelization_Sebastian.Rmd\")`\n:::\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\navailableCores()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nsystem \n    12 \n```\n\n\n:::\n:::\n\n:::\n::::\n\n## plan(multisession) & plan(multicore)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplan(multicore)\n\na %<-% {\n  Sys.sleep(3)\n  a <- 1\n}\nb %<-% {\n  Sys.sleep(3)\n  b <- 2\n}\nc %<-% {\n  Sys.sleep(3)\n  c <- 3\n}\n...\nk %<-% {\n  Sys.sleep(3)\n  e <- 5\n}\n\na + b + c + d + e + f + g + h + i + j + k\n```\n:::\n\n\n. . .\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 60\n   user  system elapsed \n  0.214   0.229   3.193 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n## plan(cluster)\n\n-   To some degree a wrapper around `parallel::makeCluster()`\n-   For example:\n    -   3 connected nodes (computers) named `n1:n3`\n    -   Each with 16 CPUs\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplan(cluster, workers = c(\"n1\", \"n2\", \"n3\"))\n```\n:::\n\n\n. . .\n\nSpecialized R package for interfacing with common HPC job schedulers exists: `future.batchtools`\n\n::: {.notes}\nStill not release 1.0.0, but work afaik. Say you have access to three nodes, `n1:n3`. This will then create a set of copies of R running in parallel and communicating over sockets between them.\n\nI have not tried this yet, as it is one thing to need to work in parallel with for example 8 or 16 cores on the HPC, but another use case to need 3 whole nodes for example.\n:::\n\n##  {background-image=\"/assets/images/cover.jpg\"}\n\n### Thank you! Questions?\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n         _                  \nplatform x86_64-pc-linux-gnu\nos       linux-gnu          \nmajor    4                  \nminor    3.2                \n```\n\n\n:::\n:::\n\n\n[{{< meta current_year >}} • [SciLifeLab](https://www.scilifelab.se/) • [NBIS](https://nbis.se/) • [RaukR](https://nbisweden.github.io/raukr-2024)]{.smaller}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}